{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "afb70a9e-ab2d-488b-8aac-ff1255f1573f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alpha\\AppData\\Local\\Temp\\ipykernel_21368\\703697880.py:25: FutureWarning: reindexing with a non-unique Index is deprecated and will raise in a future version.\n",
      "  df = df.reindex(desired_years).reset_index().fillna(0)\n",
      "C:\\Users\\Alpha\\AppData\\Local\\Temp\\ipykernel_21368\\703697880.py:25: FutureWarning: reindexing with a non-unique Index is deprecated and will raise in a future version.\n",
      "  df = df.reindex(desired_years).reset_index().fillna(0)\n",
      "C:\\Users\\Alpha\\AppData\\Local\\Temp\\ipykernel_21368\\703697880.py:25: FutureWarning: reindexing with a non-unique Index is deprecated and will raise in a future version.\n",
      "  df = df.reindex(desired_years).reset_index().fillna(0)\n",
      "C:\\Users\\Alpha\\AppData\\Local\\Temp\\ipykernel_21368\\703697880.py:25: FutureWarning: reindexing with a non-unique Index is deprecated and will raise in a future version.\n",
      "  df = df.reindex(desired_years).reset_index().fillna(0)\n",
      "C:\\Users\\Alpha\\AppData\\Local\\Temp\\ipykernel_21368\\703697880.py:25: FutureWarning: reindexing with a non-unique Index is deprecated and will raise in a future version.\n",
      "  df = df.reindex(desired_years).reset_index().fillna(0)\n",
      "C:\\Users\\Alpha\\AppData\\Local\\Temp\\ipykernel_21368\\703697880.py:25: FutureWarning: reindexing with a non-unique Index is deprecated and will raise in a future version.\n",
      "  df = df.reindex(desired_years).reset_index().fillna(0)\n",
      "C:\\Users\\Alpha\\AppData\\Local\\Temp\\ipykernel_21368\\703697880.py:25: FutureWarning: reindexing with a non-unique Index is deprecated and will raise in a future version.\n",
      "  df = df.reindex(desired_years).reset_index().fillna(0)\n",
      "C:\\Users\\Alpha\\AppData\\Local\\Temp\\ipykernel_21368\\703697880.py:25: FutureWarning: reindexing with a non-unique Index is deprecated and will raise in a future version.\n",
      "  df = df.reindex(desired_years).reset_index().fillna(0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Columns in C:\\Users\\Alpha\\OneDrive - Seolotsen\\03_SEO\\01_1_Data Analyst Portfolio\\Git_Repo\\Stackfuel_Data_Analyst\\01_CSV_Ressources\\003-annual-change-renewables.csv don't match the initial structure. File is skipped.\n",
      "Warning: Columns in C:\\Users\\Alpha\\OneDrive - Seolotsen\\03_SEO\\01_1_Data Analyst Portfolio\\Git_Repo\\Stackfuel_Data_Analyst\\01_CSV_Ressources\\005-annual-co2-flaring.csv don't match the initial structure. File is skipped.\n",
      "Warning: Columns in C:\\Users\\Alpha\\OneDrive - Seolotsen\\03_SEO\\01_1_Data Analyst Portfolio\\Git_Repo\\Stackfuel_Data_Analyst\\01_CSV_Ressources\\006-annual-co2-gas.csv don't match the initial structure. File is skipped.\n",
      "Warning: Columns in C:\\Users\\Alpha\\OneDrive - Seolotsen\\03_SEO\\01_1_Data Analyst Portfolio\\Git_Repo\\Stackfuel_Data_Analyst\\01_CSV_Ressources\\007-annual-co2-oil.csv don't match the initial structure. File is skipped.\n",
      "Warning: Columns in C:\\Users\\Alpha\\OneDrive - Seolotsen\\03_SEO\\01_1_Data Analyst Portfolio\\Git_Repo\\Stackfuel_Data_Analyst\\01_CSV_Ressources\\008-annual-co2-coal.csv don't match the initial structure. File is skipped.\n",
      "Warning: Columns in C:\\Users\\Alpha\\OneDrive - Seolotsen\\03_SEO\\01_1_Data Analyst Portfolio\\Git_Repo\\Stackfuel_Data_Analyst\\01_CSV_Ressources\\009-primary-energy-cons.csv don't match the initial structure. File is skipped.\n",
      "Warning: Columns in C:\\Users\\Alpha\\OneDrive - Seolotsen\\03_SEO\\01_1_Data Analyst Portfolio\\Git_Repo\\Stackfuel_Data_Analyst\\01_CSV_Ressources\\011-global-warming-fossil.csv don't match the initial structure. File is skipped.\n",
      "Warning: Columns in C:\\Users\\Alpha\\OneDrive - Seolotsen\\03_SEO\\01_1_Data Analyst Portfolio\\Git_Repo\\Stackfuel_Data_Analyst\\01_CSV_Ressources\\012-total-ghg-emissions.csv don't match the initial structure. File is skipped.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alpha\\AppData\\Local\\Temp\\ipykernel_21368\\703697880.py:25: FutureWarning: reindexing with a non-unique Index is deprecated and will raise in a future version.\n",
      "  df = df.reindex(desired_years).reset_index().fillna(0)\n",
      "C:\\Users\\Alpha\\AppData\\Local\\Temp\\ipykernel_21368\\703697880.py:25: FutureWarning: reindexing with a non-unique Index is deprecated and will raise in a future version.\n",
      "  df = df.reindex(desired_years).reset_index().fillna(0)\n",
      "C:\\Users\\Alpha\\AppData\\Local\\Temp\\ipykernel_21368\\703697880.py:25: FutureWarning: reindexing with a non-unique Index is deprecated and will raise in a future version.\n",
      "  df = df.reindex(desired_years).reset_index().fillna(0)\n",
      "C:\\Users\\Alpha\\AppData\\Local\\Temp\\ipykernel_21368\\703697880.py:25: FutureWarning: reindexing with a non-unique Index is deprecated and will raise in a future version.\n",
      "  df = df.reindex(desired_years).reset_index().fillna(0)\n",
      "C:\\Users\\Alpha\\AppData\\Local\\Temp\\ipykernel_21368\\703697880.py:25: FutureWarning: reindexing with a non-unique Index is deprecated and will raise in a future version.\n",
      "  df = df.reindex(desired_years).reset_index().fillna(0)\n",
      "C:\\Users\\Alpha\\AppData\\Local\\Temp\\ipykernel_21368\\703697880.py:25: FutureWarning: reindexing with a non-unique Index is deprecated and will raise in a future version.\n",
      "  df = df.reindex(desired_years).reset_index().fillna(0)\n",
      "C:\\Users\\Alpha\\AppData\\Local\\Temp\\ipykernel_21368\\703697880.py:25: FutureWarning: reindexing with a non-unique Index is deprecated and will raise in a future version.\n",
      "  df = df.reindex(desired_years).reset_index().fillna(0)\n",
      "C:\\Users\\Alpha\\AppData\\Local\\Temp\\ipykernel_21368\\703697880.py:25: FutureWarning: reindexing with a non-unique Index is deprecated and will raise in a future version.\n",
      "  df = df.reindex(desired_years).reset_index().fillna(0)\n",
      "C:\\Users\\Alpha\\AppData\\Local\\Temp\\ipykernel_21368\\703697880.py:25: FutureWarning: reindexing with a non-unique Index is deprecated and will raise in a future version.\n",
      "  df = df.reindex(desired_years).reset_index().fillna(0)\n",
      "C:\\Users\\Alpha\\AppData\\Local\\Temp\\ipykernel_21368\\703697880.py:25: FutureWarning: reindexing with a non-unique Index is deprecated and will raise in a future version.\n",
      "  df = df.reindex(desired_years).reset_index().fillna(0)\n",
      "C:\\Users\\Alpha\\AppData\\Local\\Temp\\ipykernel_21368\\703697880.py:25: FutureWarning: reindexing with a non-unique Index is deprecated and will raise in a future version.\n",
      "  df = df.reindex(desired_years).reset_index().fillna(0)\n",
      "C:\\Users\\Alpha\\AppData\\Local\\Temp\\ipykernel_21368\\703697880.py:25: FutureWarning: reindexing with a non-unique Index is deprecated and will raise in a future version.\n",
      "  df = df.reindex(desired_years).reset_index().fillna(0)\n",
      "C:\\Users\\Alpha\\AppData\\Local\\Temp\\ipykernel_21368\\703697880.py:25: FutureWarning: reindexing with a non-unique Index is deprecated and will raise in a future version.\n",
      "  df = df.reindex(desired_years).reset_index().fillna(0)\n",
      "C:\\Users\\Alpha\\AppData\\Local\\Temp\\ipykernel_21368\\703697880.py:25: FutureWarning: reindexing with a non-unique Index is deprecated and will raise in a future version.\n",
      "  df = df.reindex(desired_years).reset_index().fillna(0)\n",
      "C:\\Users\\Alpha\\AppData\\Local\\Temp\\ipykernel_21368\\703697880.py:25: FutureWarning: reindexing with a non-unique Index is deprecated and will raise in a future version.\n",
      "  df = df.reindex(desired_years).reset_index().fillna(0)\n",
      "C:\\Users\\Alpha\\AppData\\Local\\Temp\\ipykernel_21368\\703697880.py:25: FutureWarning: reindexing with a non-unique Index is deprecated and will raise in a future version.\n",
      "  df = df.reindex(desired_years).reset_index().fillna(0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Columns in C:\\Users\\Alpha\\OneDrive - Seolotsen\\03_SEO\\01_1_Data Analyst Portfolio\\Git_Repo\\Stackfuel_Data_Analyst\\01_CSV_Ressources\\electricity-fossil-fuels.csv don't match the initial structure. File is skipped.\n",
      "Warning: Columns in C:\\Users\\Alpha\\OneDrive - Seolotsen\\03_SEO\\01_1_Data Analyst Portfolio\\Git_Repo\\Stackfuel_Data_Analyst\\01_CSV_Ressources\\electricity-production-by-source.csv don't match the initial structure. File is skipped.\n",
      "Warning: Columns in C:\\Users\\Alpha\\OneDrive - Seolotsen\\03_SEO\\01_1_Data Analyst Portfolio\\Git_Repo\\Stackfuel_Data_Analyst\\01_CSV_Ressources\\energy-consumption-by-source-and-country.csv don't match the initial structure. File is skipped.\n",
      "Warning: Columns in C:\\Users\\Alpha\\OneDrive - Seolotsen\\03_SEO\\01_1_Data Analyst Portfolio\\Git_Repo\\Stackfuel_Data_Analyst\\01_CSV_Ressources\\energy-intensity (1).csv don't match the initial structure. File is skipped.\n",
      "Warning: Columns in C:\\Users\\Alpha\\OneDrive - Seolotsen\\03_SEO\\01_1_Data Analyst Portfolio\\Git_Repo\\Stackfuel_Data_Analyst\\01_CSV_Ressources\\energy-intensity.csv don't match the initial structure. File is skipped.\n",
      "Warning: Columns in C:\\Users\\Alpha\\OneDrive - Seolotsen\\03_SEO\\01_1_Data Analyst Portfolio\\Git_Repo\\Stackfuel_Data_Analyst\\01_CSV_Ressources\\installed-global-renewable-energy-capacity-by-technology.csv don't match the initial structure. File is skipped.\n",
      "Warning: Columns in C:\\Users\\Alpha\\OneDrive - Seolotsen\\03_SEO\\01_1_Data Analyst Portfolio\\Git_Repo\\Stackfuel_Data_Analyst\\01_CSV_Ressources\\levelized-cost-of-energy.csv don't match the initial structure. File is skipped.\n",
      "Warning: Columns in C:\\Users\\Alpha\\OneDrive - Seolotsen\\03_SEO\\01_1_Data Analyst Portfolio\\Git_Repo\\Stackfuel_Data_Analyst\\01_CSV_Ressources\\low-carbon-electricity.csv don't match the initial structure. File is skipped.\n",
      "Warning: Columns in C:\\Users\\Alpha\\OneDrive - Seolotsen\\03_SEO\\01_1_Data Analyst Portfolio\\Git_Repo\\Stackfuel_Data_Analyst\\01_CSV_Ressources\\national-gdp-constant-usd-wb portfolio.csv don't match the initial structure. File is skipped.\n",
      "Warning: Columns in C:\\Users\\Alpha\\OneDrive - Seolotsen\\03_SEO\\01_1_Data Analyst Portfolio\\Git_Repo\\Stackfuel_Data_Analyst\\01_CSV_Ressources\\renewable-energy-investment-of-gdp.csv don't match the initial structure. File is skipped.\n",
      "Warning: Columns in C:\\Users\\Alpha\\OneDrive - Seolotsen\\03_SEO\\01_1_Data Analyst Portfolio\\Git_Repo\\Stackfuel_Data_Analyst\\01_CSV_Ressources\\renewable-share-energy (2).csv don't match the initial structure. File is skipped.\n",
      "Warning: Columns in C:\\Users\\Alpha\\OneDrive - Seolotsen\\03_SEO\\01_1_Data Analyst Portfolio\\Git_Repo\\Stackfuel_Data_Analyst\\01_CSV_Ressources\\renewable-share-energy.csv don't match the initial structure. File is skipped.\n",
      "Warning: Columns in C:\\Users\\Alpha\\OneDrive - Seolotsen\\03_SEO\\01_1_Data Analyst Portfolio\\Git_Repo\\Stackfuel_Data_Analyst\\01_CSV_Ressources\\share-of-electricity-production-from-renewable-sources.csv don't match the initial structure. File is skipped.\n",
      "Warning: Columns in C:\\Users\\Alpha\\OneDrive - Seolotsen\\03_SEO\\01_1_Data Analyst Portfolio\\Git_Repo\\Stackfuel_Data_Analyst\\01_CSV_Ressources\\solar-pv-cumulative-capacity.csv don't match the initial structure. File is skipped.\n",
      "Warning: Columns in C:\\Users\\Alpha\\OneDrive - Seolotsen\\03_SEO\\01_1_Data Analyst Portfolio\\Git_Repo\\Stackfuel_Data_Analyst\\01_CSV_Ressources\\total-ghg-emissions.csv don't match the initial structure. File is skipped.\n",
      "Warning: Columns in C:\\Users\\Alpha\\OneDrive - Seolotsen\\03_SEO\\01_1_Data Analyst Portfolio\\Git_Repo\\Stackfuel_Data_Analyst\\01_CSV_Ressources\\wind-energy-consumption-vs-installed-wind-energy-capacity.csv don't match the initial structure. File is skipped.\n",
      "Warning: Columns in C:\\Users\\Alpha\\OneDrive - Seolotsen\\03_SEO\\01_1_Data Analyst Portfolio\\Git_Repo\\Stackfuel_Data_Analyst\\01_CSV_Ressources\\wind-generation.csv don't match the initial structure. File is skipped.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alpha\\AppData\\Local\\Temp\\ipykernel_21368\\703697880.py:25: FutureWarning: reindexing with a non-unique Index is deprecated and will raise in a future version.\n",
      "  df = df.reindex(desired_years).reset_index().fillna(0)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No objects to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[78], line 37\u001b[0m\n\u001b[0;32m     34\u001b[0m         error_files\u001b[38;5;241m.\u001b[39mappend(filename)\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# Zusammenführen der DataFrames\u001b[39;00m\n\u001b[1;32m---> 37\u001b[0m final_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat(list_of_dfs, ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# Ausgabe der Dateiübersicht\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mSuccessfully read files:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:368\u001b[0m, in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[38;5;129m@deprecate_nonkeyword_arguments\u001b[39m(version\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, allowed_args\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjs\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconcat\u001b[39m(\n\u001b[0;32m    148\u001b[0m     objs: Iterable[NDFrame] \u001b[38;5;241m|\u001b[39m Mapping[HashableT, NDFrame],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    157\u001b[0m     copy: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    158\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m    159\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;124;03m    Concatenate pandas objects along a particular axis.\u001b[39;00m\n\u001b[0;32m    161\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    366\u001b[0m \u001b[38;5;124;03m    1   3   4\u001b[39;00m\n\u001b[0;32m    367\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 368\u001b[0m     op \u001b[38;5;241m=\u001b[39m _Concatenator(\n\u001b[0;32m    369\u001b[0m         objs,\n\u001b[0;32m    370\u001b[0m         axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[0;32m    371\u001b[0m         ignore_index\u001b[38;5;241m=\u001b[39mignore_index,\n\u001b[0;32m    372\u001b[0m         join\u001b[38;5;241m=\u001b[39mjoin,\n\u001b[0;32m    373\u001b[0m         keys\u001b[38;5;241m=\u001b[39mkeys,\n\u001b[0;32m    374\u001b[0m         levels\u001b[38;5;241m=\u001b[39mlevels,\n\u001b[0;32m    375\u001b[0m         names\u001b[38;5;241m=\u001b[39mnames,\n\u001b[0;32m    376\u001b[0m         verify_integrity\u001b[38;5;241m=\u001b[39mverify_integrity,\n\u001b[0;32m    377\u001b[0m         copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[0;32m    378\u001b[0m         sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[0;32m    379\u001b[0m     )\n\u001b[0;32m    381\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:425\u001b[0m, in \u001b[0;36m_Concatenator.__init__\u001b[1;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[0;32m    422\u001b[0m     objs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(objs)\n\u001b[0;32m    424\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(objs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 425\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo objects to concatenate\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    427\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keys \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    428\u001b[0m     objs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(com\u001b[38;5;241m.\u001b[39mnot_none(\u001b[38;5;241m*\u001b[39mobjs))\n",
      "\u001b[1;31mValueError\u001b[0m: No objects to concatenate"
     ]
    }
   ],
   "source": [
    "### from here are errors -- years and countries must match between 1965 to 2022 and missing valuues must null\n",
    "# Verzeichnis definieren\n",
    "path = r\"C:\\Users\\Alpha\\OneDrive - Seolotsen\\03_SEO\\01_1_Data Analyst Portfolio\\Git_Repo\\Stackfuel_Data_Analyst\\01_CSV_Ressources\\*.csv\"\n",
    "\n",
    "# Liste aller CSV-Dateien im Verzeichnis mit glob\n",
    "all_files = glob.glob(path)\n",
    "\n",
    "# Listen zum Speichern der Dateinamen\n",
    "successful_files = []\n",
    "error_files = []\n",
    "\n",
    "# Definieren des Zeitraums, den wir abdecken möchten\n",
    "desired_years = list(range(1965, 2023))\n",
    "\n",
    "# Alle anderen Dateien einlesen\n",
    "for filename in all_files[1:]:\n",
    "    try:\n",
    "        df = pd.read_csv(filename, on_bad_lines='warn')\n",
    "\n",
    "        # Filtern Sie den DataFrame, um nur Zeilen zwischen 1965 und 2022 zu behalten\n",
    "        df = df[df['Year'].between(1965, 2022)]\n",
    "\n",
    "        # Reindizieren Sie den DataFrame, um sicherzustellen, dass er alle Jahre von 1965 bis 2022 enthält\n",
    "        df.set_index('Year', inplace=True)\n",
    "        df = df.reindex(desired_years).reset_index().fillna(0)\n",
    "\n",
    "        list_of_dfs.append(df)\n",
    "        successful_files.append(filename)\n",
    "    except ValueError:\n",
    "        print(f\"Warning: Columns in {filename} don't match the initial structure. File is skipped.\")\n",
    "        error_files.append(filename)\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {filename}: {e}\")\n",
    "        error_files.append(filename)\n",
    "\n",
    "# Zusammenführen der DataFrames\n",
    "final_df = pd.concat(list_of_dfs, ignore_index=True)\n",
    "\n",
    "# Ausgabe der Dateiübersicht\n",
    "print(\"\\nSuccessfully read files:\")\n",
    "for fname in successful_files:\n",
    "    print(fname)\n",
    "\n",
    "print(\"\\nFiles with errors:\")\n",
    "for fname in error_files:\n",
    "    print(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "5a134159-4d99-46ab-90c9-091ef1fc3522",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Entity</th>\n",
       "      <th>Code</th>\n",
       "      <th>Electricity from wind (TWh)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>\"ASEAN (Ember)\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001</th>\n",
       "      <td>\"ASEAN (Ember)\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002</th>\n",
       "      <td>\"ASEAN (Ember)\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003</th>\n",
       "      <td>\"ASEAN (Ember)\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004</th>\n",
       "      <td>\"ASEAN (Ember)\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>\"Zimbabwe\"</td>\n",
       "      <td>ZWE</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>\"Zimbabwe\"</td>\n",
       "      <td>ZWE</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>\"Zimbabwe\"</td>\n",
       "      <td>ZWE</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020</th>\n",
       "      <td>\"Zimbabwe\"</td>\n",
       "      <td>ZWE</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021</th>\n",
       "      <td>\"Zimbabwe\"</td>\n",
       "      <td>ZWE</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7996 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Entity Code  Electricity from wind (TWh)\n",
       "Year                                                   \n",
       "2000  \"ASEAN (Ember)\"  NaN                          0.0\n",
       "2001  \"ASEAN (Ember)\"  NaN                          0.0\n",
       "2002  \"ASEAN (Ember)\"  NaN                          0.0\n",
       "2003  \"ASEAN (Ember)\"  NaN                          0.0\n",
       "2004  \"ASEAN (Ember)\"  NaN                          0.0\n",
       "...               ...  ...                          ...\n",
       "2017       \"Zimbabwe\"  ZWE                          0.0\n",
       "2018       \"Zimbabwe\"  ZWE                          0.0\n",
       "2019       \"Zimbabwe\"  ZWE                          0.0\n",
       "2020       \"Zimbabwe\"  ZWE                          0.0\n",
       "2021       \"Zimbabwe\"  ZWE                          0.0\n",
       "\n",
       "[7996 rows x 3 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "8b2defb4-09d7-46b3-81ce-b9f034e88a7d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alpha\\AppData\\Local\\Temp\\ipykernel_21368\\972998706.py:23: FutureWarning: reindexing with a non-unique Index is deprecated and will raise in a future version.\n",
      "  first_df = first_df.reindex(desired_years).reset_index().fillna(0)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reindex on an axis with duplicate labels",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[84], line 23\u001b[0m\n\u001b[0;32m     21\u001b[0m first_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(all_files[\u001b[38;5;241m0\u001b[39m], on_bad_lines\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwarn\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     22\u001b[0m first_df\u001b[38;5;241m.\u001b[39mset_index(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYear\u001b[39m\u001b[38;5;124m'\u001b[39m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 23\u001b[0m first_df \u001b[38;5;241m=\u001b[39m first_df\u001b[38;5;241m.\u001b[39mreindex(desired_years)\u001b[38;5;241m.\u001b[39mreset_index()\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     24\u001b[0m list_of_dfs\u001b[38;5;241m.\u001b[39mappend(first_df)\n\u001b[0;32m     25\u001b[0m successful_files\u001b[38;5;241m.\u001b[39mappend(all_files[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\util\\_decorators.py:347\u001b[0m, in \u001b[0;36mrewrite_axis_style_signature.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[0;32m    346\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Callable[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, Any]:\n\u001b[1;32m--> 347\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:5205\u001b[0m, in \u001b[0;36mDataFrame.reindex\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   5203\u001b[0m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maxis\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m   5204\u001b[0m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m-> 5205\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mreindex(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:5289\u001b[0m, in \u001b[0;36mNDFrame.reindex\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   5286\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_multi(axes, copy, fill_value)\n\u001b[0;32m   5288\u001b[0m \u001b[38;5;66;03m# perform the reindex on the axes\u001b[39;00m\n\u001b[1;32m-> 5289\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_axes(\n\u001b[0;32m   5290\u001b[0m     axes, level, limit, tolerance, method, fill_value, copy\n\u001b[0;32m   5291\u001b[0m )\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreindex\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:5004\u001b[0m, in \u001b[0;36mDataFrame._reindex_axes\u001b[1;34m(self, axes, level, limit, tolerance, method, fill_value, copy)\u001b[0m\n\u001b[0;32m   5002\u001b[0m index \u001b[38;5;241m=\u001b[39m axes[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   5003\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 5004\u001b[0m     frame \u001b[38;5;241m=\u001b[39m frame\u001b[38;5;241m.\u001b[39m_reindex_index(\n\u001b[0;32m   5005\u001b[0m         index, method, copy, level, fill_value, limit, tolerance\n\u001b[0;32m   5006\u001b[0m     )\n\u001b[0;32m   5008\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frame\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:5023\u001b[0m, in \u001b[0;36mDataFrame._reindex_index\u001b[1;34m(self, new_index, method, copy, level, fill_value, limit, tolerance)\u001b[0m\n\u001b[0;32m   5010\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_reindex_index\u001b[39m(\n\u001b[0;32m   5011\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   5012\u001b[0m     new_index,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5018\u001b[0m     tolerance\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   5019\u001b[0m ):\n\u001b[0;32m   5020\u001b[0m     new_index, indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mreindex(\n\u001b[0;32m   5021\u001b[0m         new_index, method\u001b[38;5;241m=\u001b[39mmethod, level\u001b[38;5;241m=\u001b[39mlevel, limit\u001b[38;5;241m=\u001b[39mlimit, tolerance\u001b[38;5;241m=\u001b[39mtolerance\n\u001b[0;32m   5022\u001b[0m     )\n\u001b[1;32m-> 5023\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_with_indexers(\n\u001b[0;32m   5024\u001b[0m         {\u001b[38;5;241m0\u001b[39m: [new_index, indexer]},\n\u001b[0;32m   5025\u001b[0m         copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[0;32m   5026\u001b[0m         fill_value\u001b[38;5;241m=\u001b[39mfill_value,\n\u001b[0;32m   5027\u001b[0m         allow_dups\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   5028\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:5355\u001b[0m, in \u001b[0;36mNDFrame._reindex_with_indexers\u001b[1;34m(self, reindexers, fill_value, copy, allow_dups)\u001b[0m\n\u001b[0;32m   5352\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m ensure_platform_int(indexer)\n\u001b[0;32m   5354\u001b[0m \u001b[38;5;66;03m# TODO: speed up on homogeneous DataFrame objects (see _reindex_multi)\u001b[39;00m\n\u001b[1;32m-> 5355\u001b[0m new_data \u001b[38;5;241m=\u001b[39m new_data\u001b[38;5;241m.\u001b[39mreindex_indexer(\n\u001b[0;32m   5356\u001b[0m     index,\n\u001b[0;32m   5357\u001b[0m     indexer,\n\u001b[0;32m   5358\u001b[0m     axis\u001b[38;5;241m=\u001b[39mbaxis,\n\u001b[0;32m   5359\u001b[0m     fill_value\u001b[38;5;241m=\u001b[39mfill_value,\n\u001b[0;32m   5360\u001b[0m     allow_dups\u001b[38;5;241m=\u001b[39mallow_dups,\n\u001b[0;32m   5361\u001b[0m     copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[0;32m   5362\u001b[0m )\n\u001b[0;32m   5363\u001b[0m \u001b[38;5;66;03m# If we've made a copy once, no need to make another one\u001b[39;00m\n\u001b[0;32m   5364\u001b[0m copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:737\u001b[0m, in \u001b[0;36mBaseBlockManager.reindex_indexer\u001b[1;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy, only_slice, use_na_proxy)\u001b[0m\n\u001b[0;32m    735\u001b[0m \u001b[38;5;66;03m# some axes don't allow reindexing with dups\u001b[39;00m\n\u001b[0;32m    736\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_dups:\n\u001b[1;32m--> 737\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes[axis]\u001b[38;5;241m.\u001b[39m_validate_can_reindex(indexer)\n\u001b[0;32m    739\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim:\n\u001b[0;32m    740\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRequested axis not found in manager\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:4316\u001b[0m, in \u001b[0;36mIndex._validate_can_reindex\u001b[1;34m(self, indexer)\u001b[0m\n\u001b[0;32m   4314\u001b[0m \u001b[38;5;66;03m# trying to reindex on an axis with duplicates\u001b[39;00m\n\u001b[0;32m   4315\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_as_unique \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(indexer):\n\u001b[1;32m-> 4316\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot reindex on an axis with duplicate labels\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reindex on an axis with duplicate labels"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "# Verzeichnis definieren\n",
    "path = r\"C:\\Users\\Alpha\\OneDrive - Seolotsen\\03_SEO\\01_1_Data Analyst Portfolio\\Git_Repo\\Stackfuel_Data_Analyst\\01_CSV_Ressources\\*.csv\"\n",
    "\n",
    "# Liste aller CSV-Dateien im Verzeichnis mit glob\n",
    "all_files = glob.glob(path)\n",
    "\n",
    "# Listen zum Speichern der Dateinamen\n",
    "successful_files = []\n",
    "error_files = []\n",
    "\n",
    "# Definieren des Zeitraums, den wir abdecken möchten\n",
    "desired_years = list(range(1965, 2023))\n",
    "\n",
    "list_of_dfs = []\n",
    "\n",
    "# Erste Datei separat einlesen und auf den gewünschten Zeitraum erweitern\n",
    "first_df = pd.read_csv(all_files[0], on_bad_lines='warn')\n",
    "first_df.set_index('Year', inplace=True)\n",
    "first_df = first_df.reindex(desired_years).reset_index().fillna(0)\n",
    "list_of_dfs.append(first_df)\n",
    "successful_files.append(all_files[0])\n",
    "\n",
    "# Alle anderen Dateien einlesen\n",
    "for filename in all_files[1:]:\n",
    "    try:\n",
    "        df = pd.read_csv(filename, on_bad_lines='warn')\n",
    "\n",
    "        # Filtern Sie den DataFrame, um nur Zeilen zwischen 1965 und 2022 zu behalten\n",
    "        df.set_index('Year', inplace=True)\n",
    "        df = df.reindex(desired_years).reset_index().fillna(0)\n",
    "\n",
    "        list_of_dfs.append(df)\n",
    "        successful_files.append(filename)\n",
    "    except ValueError:\n",
    "        print(f\"Warning: Columns in {filename} don't match the initial structure. File is skipped.\")\n",
    "        error_files.append(filename)\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {filename}: {e}\")\n",
    "        error_files.append(filename)\n",
    "\n",
    "# Zusammenführen der DataFrames\n",
    "final_df = pd.concat(list_of_dfs, ignore_index=True)\n",
    "\n",
    "# Ausgabe der Dateiübersicht\n",
    "print(\"\\nSuccessfully read files:\")\n",
    "for fname in successful_files:\n",
    "    print(fname)\n",
    "\n",
    "print(\"\\nFiles with errors:\")\n",
    "for fname in error_files:\n",
    "    print(fname)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3243c31a-7e33-4dd6-88d3-defb98cc43a0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Entity</th>\n",
       "      <th>Code</th>\n",
       "      <th>Electricity from wind (TWh)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>\"ASEAN (Ember)\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001</th>\n",
       "      <td>\"ASEAN (Ember)\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002</th>\n",
       "      <td>\"ASEAN (Ember)\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003</th>\n",
       "      <td>\"ASEAN (Ember)\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004</th>\n",
       "      <td>\"ASEAN (Ember)\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>\"Zimbabwe\"</td>\n",
       "      <td>ZWE</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>\"Zimbabwe\"</td>\n",
       "      <td>ZWE</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>\"Zimbabwe\"</td>\n",
       "      <td>ZWE</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020</th>\n",
       "      <td>\"Zimbabwe\"</td>\n",
       "      <td>ZWE</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021</th>\n",
       "      <td>\"Zimbabwe\"</td>\n",
       "      <td>ZWE</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7996 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Entity Code  Electricity from wind (TWh)\n",
       "Year                                                   \n",
       "2000  \"ASEAN (Ember)\"  NaN                          0.0\n",
       "2001  \"ASEAN (Ember)\"  NaN                          0.0\n",
       "2002  \"ASEAN (Ember)\"  NaN                          0.0\n",
       "2003  \"ASEAN (Ember)\"  NaN                          0.0\n",
       "2004  \"ASEAN (Ember)\"  NaN                          0.0\n",
       "...               ...  ...                          ...\n",
       "2017       \"Zimbabwe\"  ZWE                          0.0\n",
       "2018       \"Zimbabwe\"  ZWE                          0.0\n",
       "2019       \"Zimbabwe\"  ZWE                          0.0\n",
       "2020       \"Zimbabwe\"  ZWE                          0.0\n",
       "2021       \"Zimbabwe\"  ZWE                          0.0\n",
       "\n",
       "[7996 rows x 3 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd6006c-e7b3-4c41-9d50-78d661963a18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "1932fdee-7fe7-43f0-940f-a12e24c22146",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alpha\\AppData\\Local\\Temp\\ipykernel_21368\\987903097.py:30: FutureWarning: reindexing with a non-unique Index is deprecated and will raise in a future version.\n",
      "  df = df.reindex(desired_years).reset_index().fillna(0)\n",
      "C:\\Users\\Alpha\\AppData\\Local\\Temp\\ipykernel_21368\\987903097.py:30: FutureWarning: reindexing with a non-unique Index is deprecated and will raise in a future version.\n",
      "  df = df.reindex(desired_years).reset_index().fillna(0)\n",
      "C:\\Users\\Alpha\\AppData\\Local\\Temp\\ipykernel_21368\\987903097.py:30: FutureWarning: reindexing with a non-unique Index is deprecated and will raise in a future version.\n",
      "  df = df.reindex(desired_years).reset_index().fillna(0)\n",
      "C:\\Users\\Alpha\\AppData\\Local\\Temp\\ipykernel_21368\\987903097.py:30: FutureWarning: reindexing with a non-unique Index is deprecated and will raise in a future version.\n",
      "  df = df.reindex(desired_years).reset_index().fillna(0)\n",
      "C:\\Users\\Alpha\\AppData\\Local\\Temp\\ipykernel_21368\\987903097.py:30: FutureWarning: reindexing with a non-unique Index is deprecated and will raise in a future version.\n",
      "  df = df.reindex(desired_years).reset_index().fillna(0)\n",
      "C:\\Users\\Alpha\\AppData\\Local\\Temp\\ipykernel_21368\\987903097.py:30: FutureWarning: reindexing with a non-unique Index is deprecated and will raise in a future version.\n",
      "  df = df.reindex(desired_years).reset_index().fillna(0)\n",
      "C:\\Users\\Alpha\\AppData\\Local\\Temp\\ipykernel_21368\\987903097.py:30: FutureWarning: reindexing with a non-unique Index is deprecated and will raise in a future version.\n",
      "  df = df.reindex(desired_years).reset_index().fillna(0)\n",
      "C:\\Users\\Alpha\\AppData\\Local\\Temp\\ipykernel_21368\\987903097.py:30: FutureWarning: reindexing with a non-unique Index is deprecated and will raise in a future version.\n",
      "  df = df.reindex(desired_years).reset_index().fillna(0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cannot reindex on an axis with duplicate labels\n",
      "cannot reindex on an axis with duplicate labels\n",
      "cannot reindex on an axis with duplicate labels\n",
      "cannot reindex on an axis with duplicate labels\n",
      "cannot reindex on an axis with duplicate labels\n",
      "cannot reindex on an axis with duplicate labels\n",
      "cannot reindex on an axis with duplicate labels\n",
      "cannot reindex on an axis with duplicate labels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alpha\\AppData\\Local\\Temp\\ipykernel_21368\\987903097.py:30: FutureWarning: reindexing with a non-unique Index is deprecated and will raise in a future version.\n",
      "  df = df.reindex(desired_years).reset_index().fillna(0)\n",
      "C:\\Users\\Alpha\\AppData\\Local\\Temp\\ipykernel_21368\\987903097.py:30: FutureWarning: reindexing with a non-unique Index is deprecated and will raise in a future version.\n",
      "  df = df.reindex(desired_years).reset_index().fillna(0)\n",
      "C:\\Users\\Alpha\\AppData\\Local\\Temp\\ipykernel_21368\\987903097.py:30: FutureWarning: reindexing with a non-unique Index is deprecated and will raise in a future version.\n",
      "  df = df.reindex(desired_years).reset_index().fillna(0)\n",
      "C:\\Users\\Alpha\\AppData\\Local\\Temp\\ipykernel_21368\\987903097.py:30: FutureWarning: reindexing with a non-unique Index is deprecated and will raise in a future version.\n",
      "  df = df.reindex(desired_years).reset_index().fillna(0)\n",
      "C:\\Users\\Alpha\\AppData\\Local\\Temp\\ipykernel_21368\\987903097.py:30: FutureWarning: reindexing with a non-unique Index is deprecated and will raise in a future version.\n",
      "  df = df.reindex(desired_years).reset_index().fillna(0)\n",
      "C:\\Users\\Alpha\\AppData\\Local\\Temp\\ipykernel_21368\\987903097.py:30: FutureWarning: reindexing with a non-unique Index is deprecated and will raise in a future version.\n",
      "  df = df.reindex(desired_years).reset_index().fillna(0)\n",
      "C:\\Users\\Alpha\\AppData\\Local\\Temp\\ipykernel_21368\\987903097.py:30: FutureWarning: reindexing with a non-unique Index is deprecated and will raise in a future version.\n",
      "  df = df.reindex(desired_years).reset_index().fillna(0)\n",
      "C:\\Users\\Alpha\\AppData\\Local\\Temp\\ipykernel_21368\\987903097.py:30: FutureWarning: reindexing with a non-unique Index is deprecated and will raise in a future version.\n",
      "  df = df.reindex(desired_years).reset_index().fillna(0)\n",
      "C:\\Users\\Alpha\\AppData\\Local\\Temp\\ipykernel_21368\\987903097.py:30: FutureWarning: reindexing with a non-unique Index is deprecated and will raise in a future version.\n",
      "  df = df.reindex(desired_years).reset_index().fillna(0)\n",
      "C:\\Users\\Alpha\\AppData\\Local\\Temp\\ipykernel_21368\\987903097.py:30: FutureWarning: reindexing with a non-unique Index is deprecated and will raise in a future version.\n",
      "  df = df.reindex(desired_years).reset_index().fillna(0)\n",
      "C:\\Users\\Alpha\\AppData\\Local\\Temp\\ipykernel_21368\\987903097.py:30: FutureWarning: reindexing with a non-unique Index is deprecated and will raise in a future version.\n",
      "  df = df.reindex(desired_years).reset_index().fillna(0)\n",
      "C:\\Users\\Alpha\\AppData\\Local\\Temp\\ipykernel_21368\\987903097.py:30: FutureWarning: reindexing with a non-unique Index is deprecated and will raise in a future version.\n",
      "  df = df.reindex(desired_years).reset_index().fillna(0)\n",
      "C:\\Users\\Alpha\\AppData\\Local\\Temp\\ipykernel_21368\\987903097.py:30: FutureWarning: reindexing with a non-unique Index is deprecated and will raise in a future version.\n",
      "  df = df.reindex(desired_years).reset_index().fillna(0)\n",
      "C:\\Users\\Alpha\\AppData\\Local\\Temp\\ipykernel_21368\\987903097.py:30: FutureWarning: reindexing with a non-unique Index is deprecated and will raise in a future version.\n",
      "  df = df.reindex(desired_years).reset_index().fillna(0)\n",
      "C:\\Users\\Alpha\\AppData\\Local\\Temp\\ipykernel_21368\\987903097.py:30: FutureWarning: reindexing with a non-unique Index is deprecated and will raise in a future version.\n",
      "  df = df.reindex(desired_years).reset_index().fillna(0)\n",
      "C:\\Users\\Alpha\\AppData\\Local\\Temp\\ipykernel_21368\\987903097.py:30: FutureWarning: reindexing with a non-unique Index is deprecated and will raise in a future version.\n",
      "  df = df.reindex(desired_years).reset_index().fillna(0)\n",
      "C:\\Users\\Alpha\\AppData\\Local\\Temp\\ipykernel_21368\\987903097.py:30: FutureWarning: reindexing with a non-unique Index is deprecated and will raise in a future version.\n",
      "  df = df.reindex(desired_years).reset_index().fillna(0)\n",
      "C:\\Users\\Alpha\\AppData\\Local\\Temp\\ipykernel_21368\\987903097.py:30: FutureWarning: reindexing with a non-unique Index is deprecated and will raise in a future version.\n",
      "  df = df.reindex(desired_years).reset_index().fillna(0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cannot reindex on an axis with duplicate labels\n",
      "cannot reindex on an axis with duplicate labels\n",
      "cannot reindex on an axis with duplicate labels\n",
      "cannot reindex on an axis with duplicate labels\n",
      "cannot reindex on an axis with duplicate labels\n",
      "cannot reindex on an axis with duplicate labels\n",
      "cannot reindex on an axis with duplicate labels\n",
      "cannot reindex on an axis with duplicate labels\n",
      "cannot reindex on an axis with duplicate labels\n",
      "cannot reindex on an axis with duplicate labels\n",
      "cannot reindex on an axis with duplicate labels\n",
      "cannot reindex on an axis with duplicate labels\n",
      "cannot reindex on an axis with duplicate labels\n",
      "cannot reindex on an axis with duplicate labels\n",
      "cannot reindex on an axis with duplicate labels\n",
      "cannot reindex on an axis with duplicate labels\n",
      "cannot reindex on an axis with duplicate labels\n",
      "cannot reindex on an axis with duplicate labels\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No objects to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[86], line 42\u001b[0m\n\u001b[0;32m     39\u001b[0m         error_files\u001b[38;5;241m.\u001b[39mappend(filename)\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# Zusammenführen der DataFrames\u001b[39;00m\n\u001b[1;32m---> 42\u001b[0m final_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat(list_of_dfs, ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# Ausgabe der Dateiübersicht\u001b[39;00m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mSuccessfully read files:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:368\u001b[0m, in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[38;5;129m@deprecate_nonkeyword_arguments\u001b[39m(version\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, allowed_args\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjs\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconcat\u001b[39m(\n\u001b[0;32m    148\u001b[0m     objs: Iterable[NDFrame] \u001b[38;5;241m|\u001b[39m Mapping[HashableT, NDFrame],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    157\u001b[0m     copy: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    158\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m    159\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;124;03m    Concatenate pandas objects along a particular axis.\u001b[39;00m\n\u001b[0;32m    161\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    366\u001b[0m \u001b[38;5;124;03m    1   3   4\u001b[39;00m\n\u001b[0;32m    367\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 368\u001b[0m     op \u001b[38;5;241m=\u001b[39m _Concatenator(\n\u001b[0;32m    369\u001b[0m         objs,\n\u001b[0;32m    370\u001b[0m         axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[0;32m    371\u001b[0m         ignore_index\u001b[38;5;241m=\u001b[39mignore_index,\n\u001b[0;32m    372\u001b[0m         join\u001b[38;5;241m=\u001b[39mjoin,\n\u001b[0;32m    373\u001b[0m         keys\u001b[38;5;241m=\u001b[39mkeys,\n\u001b[0;32m    374\u001b[0m         levels\u001b[38;5;241m=\u001b[39mlevels,\n\u001b[0;32m    375\u001b[0m         names\u001b[38;5;241m=\u001b[39mnames,\n\u001b[0;32m    376\u001b[0m         verify_integrity\u001b[38;5;241m=\u001b[39mverify_integrity,\n\u001b[0;32m    377\u001b[0m         copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[0;32m    378\u001b[0m         sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[0;32m    379\u001b[0m     )\n\u001b[0;32m    381\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:425\u001b[0m, in \u001b[0;36m_Concatenator.__init__\u001b[1;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[0;32m    422\u001b[0m     objs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(objs)\n\u001b[0;32m    424\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(objs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 425\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo objects to concatenate\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    427\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keys \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    428\u001b[0m     objs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(com\u001b[38;5;241m.\u001b[39mnot_none(\u001b[38;5;241m*\u001b[39mobjs))\n",
      "\u001b[1;31mValueError\u001b[0m: No objects to concatenate"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "# Verzeichnis definieren\n",
    "path = r\"C:\\Users\\Alpha\\OneDrive - Seolotsen\\03_SEO\\01_1_Data Analyst Portfolio\\Git_Repo\\Stackfuel_Data_Analyst\\01_CSV_Ressources\\*.csv\"\n",
    "\n",
    "# Liste aller CSV-Dateien im Verzeichnis mit glob\n",
    "all_files = glob.glob(path)\n",
    "\n",
    "# Listen zum Speichern der Dateinamen\n",
    "successful_files = []\n",
    "error_files = []\n",
    "\n",
    "# Definieren des Zeitraums, den wir abdecken möchten\n",
    "desired_years = list(range(1965, 2023))\n",
    "\n",
    "list_of_dfs = []\n",
    "\n",
    "for filename in all_files:\n",
    "    try:\n",
    "        df = pd.read_csv(filename, on_bad_lines='warn')\n",
    "\n",
    "        # Überprüfen, ob \"Year\" Spalte vorhanden ist\n",
    "        if 'Year' not in df.columns:\n",
    "            raise ValueError(f\"File {filename} does not contain a 'Year' column.\")\n",
    "\n",
    "        # Filtern Sie den DataFrame, um nur Zeilen zwischen 1965 und 2022 zu behalten\n",
    "        df.set_index('Year', inplace=True)\n",
    "        df = df.reindex(desired_years).reset_index().fillna(0)\n",
    "\n",
    "        list_of_dfs.append(df)\n",
    "        successful_files.append(filename)\n",
    "    except ValueError as e:\n",
    "        print(e)\n",
    "        error_files.append(filename)\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {filename}: {e}\")\n",
    "        error_files.append(filename)\n",
    "\n",
    "# Zusammenführen der DataFrames\n",
    "final_df = pd.concat(list_of_dfs, ignore_index=True)\n",
    "\n",
    "# Ausgabe der Dateiübersicht\n",
    "print(\"\\nSuccessfully read files:\")\n",
    "for fname in successful_files:\n",
    "    print(fname)\n",
    "\n",
    "print(\"\\nFiles with errors:\")\n",
    "for fname in error_files:\n",
    "    print(fname)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "df87f1cb-d0eb-4b50-a9eb-62be49eb311b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Entity</th>\n",
       "      <th>Code</th>\n",
       "      <th>Year</th>\n",
       "      <th>Annual CO₂ emissions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"Afghanistan\"</td>\n",
       "      <td>AFG</td>\n",
       "      <td>1949</td>\n",
       "      <td>14656.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"Afghanistan\"</td>\n",
       "      <td>AFG</td>\n",
       "      <td>1950</td>\n",
       "      <td>84272.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"Afghanistan\"</td>\n",
       "      <td>AFG</td>\n",
       "      <td>1951</td>\n",
       "      <td>91600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"Afghanistan\"</td>\n",
       "      <td>AFG</td>\n",
       "      <td>1952</td>\n",
       "      <td>91600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"Afghanistan\"</td>\n",
       "      <td>AFG</td>\n",
       "      <td>1953</td>\n",
       "      <td>106256.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31344</th>\n",
       "      <td>\"Zimbabwe\"</td>\n",
       "      <td>ZWE</td>\n",
       "      <td>2017</td>\n",
       "      <td>9596071.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31345</th>\n",
       "      <td>\"Zimbabwe\"</td>\n",
       "      <td>ZWE</td>\n",
       "      <td>2018</td>\n",
       "      <td>11795478.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31346</th>\n",
       "      <td>\"Zimbabwe\"</td>\n",
       "      <td>ZWE</td>\n",
       "      <td>2019</td>\n",
       "      <td>11114607.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31347</th>\n",
       "      <td>\"Zimbabwe\"</td>\n",
       "      <td>ZWE</td>\n",
       "      <td>2020</td>\n",
       "      <td>10607897.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31348</th>\n",
       "      <td>\"Zimbabwe\"</td>\n",
       "      <td>ZWE</td>\n",
       "      <td>2021</td>\n",
       "      <td>11296114.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31349 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Entity Code  Year  Annual CO₂ emissions\n",
       "0      \"Afghanistan\"  AFG  1949               14656.0\n",
       "1      \"Afghanistan\"  AFG  1950               84272.0\n",
       "2      \"Afghanistan\"  AFG  1951               91600.0\n",
       "3      \"Afghanistan\"  AFG  1952               91600.0\n",
       "4      \"Afghanistan\"  AFG  1953              106256.0\n",
       "...              ...  ...   ...                   ...\n",
       "31344     \"Zimbabwe\"  ZWE  2017             9596071.0\n",
       "31345     \"Zimbabwe\"  ZWE  2018            11795478.0\n",
       "31346     \"Zimbabwe\"  ZWE  2019            11114607.0\n",
       "31347     \"Zimbabwe\"  ZWE  2020            10607897.0\n",
       "31348     \"Zimbabwe\"  ZWE  2021            11296114.0\n",
       "\n",
       "[31349 rows x 4 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
